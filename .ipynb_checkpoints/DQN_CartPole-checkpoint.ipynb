{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "    \n",
    "plt.ion()\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size=5, stride=2):\n",
    "            return (size - (kernel_size - 1) -1) // stride  + 1\n",
    "        \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "        \n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01625442  0.04467102 -0.04764312  0.04036646]\n",
      "[-0.015361   -0.1497365  -0.04683579  0.31764507]\n",
      "[-0.01835573 -0.34416117 -0.04048289  0.59519757]\n",
      "[-0.02523895 -0.1484967  -0.02857894  0.29004263]\n",
      "[-0.02820888 -0.34319973 -0.02277809  0.57357684]\n",
      "[-0.03507288 -0.53799504 -0.01130655  0.85899783]\n",
      "[-0.04583278 -0.73296116  0.00587341  1.14810427]\n",
      "[-0.060492   -0.53791638  0.02883549  0.85726892]\n",
      "[-0.07125033 -0.73341909  0.04598087  1.15887752]\n",
      "[-0.08591871 -0.92910906  0.06915842  1.46561586]\n",
      "[-0.03685408 -0.04292856 -0.03845218 -0.04640847]\n",
      "[-0.03771265  0.15272307 -0.03938035 -0.35097113]\n",
      "[-0.03465819 -0.04181736 -0.04639978 -0.07096156]\n",
      "[-0.03549454 -0.23624445 -0.04781901  0.20672854]\n",
      "[-0.04021943 -0.43065114 -0.04368444  0.48395181]\n",
      "[-0.04883245 -0.23494077 -0.0340054   0.17782719]\n",
      "[-0.05353127 -0.0393491  -0.03044886 -0.12538637]\n",
      "[-0.05431825  0.15619553 -0.03295658 -0.42751794]\n",
      "[-0.05119434  0.35176837 -0.04150694 -0.73040538]\n",
      "[-0.04415897  0.54743866 -0.05611505 -1.03585756]\n",
      "[-0.03423114 -0.00505347  0.03938902  0.01788136]\n",
      "[-0.03433221  0.18948211  0.03974665 -0.26211829]\n",
      "[-0.03054256  0.38401482  0.03450428 -0.54200446]\n",
      "[-0.02286227  0.18842534  0.02366419 -0.23865262]\n",
      "[-0.01909376  0.38320138  0.01889114 -0.52377825]\n",
      "[-0.01142973  0.18781872  0.00841558 -0.22520289]\n",
      "[-0.00767336  0.38281939  0.00391152 -0.51521939]\n",
      "[-1.69703721e-05  5.77886042e-01 -6.39286991e-03 -8.06667142e-01]\n",
      "[ 0.01154075  0.3828523  -0.02252621 -0.51600199]\n",
      "[ 0.0191978   0.18805467 -0.03284625 -0.23050184]\n",
      "[ 0.03879232  0.02347635 -0.02271339 -0.01076079]\n",
      "[ 0.03926185 -0.17131262 -0.02292861  0.27467013]\n",
      "[ 0.0358356  -0.36610005 -0.0174352   0.56003406]\n",
      "[ 0.0285136  -0.17073778 -0.00623452  0.26190951]\n",
      "[ 0.02509884 -0.36577019 -0.00099633  0.5526195 ]\n",
      "[ 0.01778344 -0.17063426  0.01005606  0.25962283]\n",
      "[ 0.01437075 -0.36589831  0.01524852  0.55546053]\n",
      "[ 0.00705278 -0.561231    0.02635773  0.85290839]\n",
      "[-0.00417184 -0.75670215  0.04341589  1.15376154]\n",
      "[-0.01930588 -0.95236263  0.06649112  1.45973596]\n",
      "[-0.04437062 -0.02581035 -0.00236144  0.03625766]\n",
      "[-0.04488683 -0.22089836 -0.00163629  0.32819459]\n",
      "[-0.04930479 -0.02575315  0.0049276   0.0349961 ]\n",
      "[-0.04981986 -0.22094542  0.00562752  0.32922966]\n",
      "[-0.05423877 -0.02590403  0.01221212  0.03832669]\n",
      "[-0.05475685  0.16904069  0.01297865 -0.25047831]\n",
      "[-0.05137603 -0.02626417  0.00796908  0.04626992]\n",
      "[-0.05190132 -0.22149948  0.00889448  0.34145647]\n",
      "[-0.05633131 -0.0265052   0.01572361  0.05159156]\n",
      "[-0.05686141  0.1683878   0.01675544 -0.23608925]\n",
      "[ 0.03892913 -0.03406259 -0.0471853  -0.01435475]\n",
      "[ 0.03824788  0.16170318 -0.04747239 -0.32154391]\n",
      "[ 0.04148194 -0.03271172 -0.05390327 -0.04420174]\n",
      "[ 0.04082771 -0.22702095 -0.0547873   0.23099889]\n",
      "[ 0.03628729 -0.42131896 -0.05016733  0.50590919]\n",
      "[ 0.02786091 -0.6156994  -0.04004914  0.78237001]\n",
      "[ 0.01554692 -0.81024869 -0.02440174  1.06218865]\n",
      "[-6.58051777e-04 -1.00503919e+00 -3.15797000e-03  1.34711402e+00]\n",
      "[-0.02075884 -1.2001213   0.02378431  1.63880728]\n",
      "[-0.04476126 -1.39551383  0.05656046  1.9388051 ]\n",
      "[0.04107621 0.0388629  0.03192181 0.03219899]\n",
      "[ 0.04185347  0.23351288  0.03256579 -0.25024381]\n",
      "[0.04652373 0.03794138 0.02756092 0.05253055]\n",
      "[ 0.04728256  0.23265752  0.02861153 -0.23133086]\n",
      "[ 0.05193571  0.4273592   0.02398491 -0.5148532 ]\n",
      "[ 0.06048289  0.62213531  0.01368784 -0.79988245]\n",
      "[ 0.0729256   0.4268283  -0.0023098  -0.50292528]\n",
      "[ 0.08146216  0.62198273 -0.01236831 -0.79633522]\n",
      "[ 0.09390182  0.42703267 -0.02829501 -0.50756869]\n",
      "[ 0.10244247  0.62254164 -0.03844639 -0.80903238]\n",
      "[0.02042951 0.00125093 0.01808513 0.0494004 ]\n",
      "[ 0.02045453  0.19610895  0.01907314 -0.23752209]\n",
      "[0.02437671 0.00071978 0.0143227  0.06111552]\n",
      "[ 0.0243911  -0.19460457  0.01554501  0.35828272]\n",
      "[0.02049901 0.00029298 0.02271066 0.07054176]\n",
      "[ 0.02050487 -0.19514708  0.0241215   0.37030261]\n",
      "[ 0.01660193 -0.39060329  0.03152755  0.67049267]\n",
      "[ 0.00878986 -0.19593352  0.0449374   0.38790069]\n",
      "[ 0.00487119 -0.00147728  0.05269542  0.10971795]\n",
      "[ 0.00484165 -0.1973132   0.05488978  0.41854934]\n",
      "[-0.02098367 -0.02963253  0.01495351 -0.02069571]\n",
      "[-0.02157633  0.16527181  0.0145396  -0.30862337]\n",
      "[-0.01827089  0.36018361  0.00836713 -0.59668567]\n",
      "[-0.01106722  0.55518748 -0.00356658 -0.88672133]\n",
      "[ 3.65327480e-05  3.60114121e-01 -2.13010101e-02 -5.95161727e-01]\n",
      "[ 0.00723882  0.55552762 -0.03320424 -0.8944775 ]\n",
      "[ 0.01834937  0.75108373 -0.05109379 -1.19741024]\n",
      "[ 0.03337104  0.94682837 -0.075042   -1.50565907]\n",
      "[ 0.05230761  1.1427761  -0.10515518 -1.82079511]\n",
      "[ 0.07516313  0.94896787 -0.14157108 -1.56254726]\n",
      "[ 0.03907544 -0.03129203 -0.01890353 -0.01362401]\n",
      "[ 0.0384496  -0.22613785 -0.01917601  0.27303519]\n",
      "[ 0.03392685 -0.42098101 -0.0137153   0.5596088 ]\n",
      "[ 0.02550723 -0.6159078  -0.00252313  0.8479393 ]\n",
      "[ 0.01318907 -0.81099524  0.01443566  1.13982774]\n",
      "[-0.00303083 -0.61606497  0.03723221  0.85170672]\n",
      "[-0.01535213 -0.42146987  0.05426635  0.57096012]\n",
      "[-0.02378153 -0.22714923  0.06568555  0.29585471]\n",
      "[-0.02832452 -0.42314311  0.07160264  0.6085092 ]\n",
      "[-0.03678738 -0.22909137  0.08377283  0.33921063]\n",
      "[-0.03407757  0.04184353 -0.00147962 -0.01049119]\n",
      "[-0.03324069 -0.15325717 -0.00168944  0.28172454]\n",
      "[-0.03630584  0.04188884  0.00394505 -0.01149076]\n",
      "[-0.03546806 -0.15328946  0.00371523  0.28243426]\n",
      "[-0.03853385 -0.34846421  0.00936392  0.57628664]\n",
      "[-0.04550313 -0.15347476  0.02088965  0.28656824]\n",
      "[-0.04857263  0.04134315  0.02662101  0.00054625]\n",
      "[-0.04774577 -0.15415028  0.02663194  0.30150814]\n",
      "[-0.05082877  0.04058217  0.0326621   0.01734191]\n",
      "[-0.05001713 -0.1549926   0.03300894  0.32014855]\n",
      "[ 0.02059434  0.04593388 -0.02289625 -0.02375287]\n",
      "[ 0.02151302  0.24137657 -0.02337131 -0.32357098]\n",
      "[ 0.02634055  0.43682339 -0.02984273 -0.62353167]\n",
      "[ 0.03507702  0.24213053 -0.04231336 -0.34039489]\n",
      "[ 0.03991963  0.43782819 -0.04912126 -0.64611505]\n",
      "[ 0.04867619  0.63359895 -0.06204356 -0.95385281]\n",
      "[ 0.06134817  0.43936411 -0.08112062 -0.68129025]\n",
      "[ 0.07013545  0.63551342 -0.09474642 -0.99836998]\n",
      "[ 0.08284572  0.83176554 -0.11471382 -1.31924164]\n",
      "[ 0.09948103  1.02813566 -0.14109866 -1.64551282]\n",
      "[0.03930125 0.04097832 0.00118324 0.00650407]\n",
      "[ 0.04012082 -0.15416059  0.00131332  0.29956009]\n",
      "[0.03703761 0.04094262 0.00730452 0.00729164]\n",
      "[ 0.03785646 -0.15428332  0.00745035  0.30227026]\n",
      "[ 0.03477079 -0.34951066  0.01349576  0.59729352]\n",
      "[ 0.02778058 -0.15458013  0.02544163  0.30889199]\n",
      "[0.02468898 0.04017025 0.03161947 0.02433998]\n",
      "[ 0.02549238 -0.15539055  0.03210627  0.32682913]\n",
      "[0.02238457 0.03925994 0.03864285 0.04444149]\n",
      "[ 0.02316977 -0.15639422  0.03953168  0.3490618 ]\n",
      "[ 0.0200233  -0.00990308 -0.00367589 -0.01012837]\n",
      "[ 0.01982524 -0.20497212 -0.00387846  0.2813925 ]\n",
      "[ 0.0157258  -0.40003854  0.00174939  0.57284966]\n",
      "[ 0.00772502 -0.20494116  0.01320639  0.28071836]\n",
      "[ 0.0036262  -0.40024898  0.01882075  0.57753711]\n",
      "[-0.00437878 -0.20539581  0.03037149  0.29084209]\n",
      "[-0.00848669 -0.40093736  0.03618834  0.592947  ]\n",
      "[-0.01650544 -0.59654671  0.04804728  0.89680596]\n",
      "[-0.02843638 -0.4021079   0.0659834   0.6196048 ]\n",
      "[-0.03647853 -0.20796656  0.07837549  0.34841155]\n",
      "[ 0.00890164 -0.04632716 -0.0406664  -0.03889821]\n",
      "[ 0.00797509  0.14935364 -0.04144436 -0.34412936]\n",
      "[ 0.01096217 -0.04515498 -0.04832695 -0.06479813]\n",
      "[ 0.01005907  0.15062534 -0.04962291 -0.37232834]\n",
      "[ 0.01307157  0.34641584 -0.05706948 -0.68023572]\n",
      "[ 0.01999989  0.15213107 -0.0706742  -0.40605234]\n",
      "[ 0.02304251 -0.04192124 -0.07879524 -0.13646144]\n",
      "[ 0.02220409 -0.23583134 -0.08152447  0.1303594 ]\n",
      "[ 0.01748746 -0.03964193 -0.07891728 -0.18688897]\n",
      "[ 0.01669462 -0.23355129 -0.08265506  0.07989219]\n",
      "[-0.03685068  0.00762093 -0.0198318  -0.01593103]\n",
      "[-0.03669826 -0.18721108 -0.02015042  0.27042934]\n",
      "[-0.04044248 -0.38203977 -0.01474184  0.55668923]\n",
      "[-0.04808328 -0.186714   -0.00360805  0.25939845]\n",
      "[-0.05181756  0.00845928  0.00157992 -0.03442031]\n",
      "[-0.05164837 -0.18668529  0.00089151  0.25876067]\n",
      "[-0.05538208  0.00842392  0.00606672 -0.03364092]\n",
      "[-0.0552136  -0.1867845   0.00539391  0.26094993]\n",
      "[-0.05894929 -0.38198304  0.0106129   0.55532927]\n",
      "[-0.06658895 -0.57725238  0.02171949  0.85133692]\n",
      "[ 0.00986414 -0.00785614 -0.02422158 -0.03548445]\n",
      "[ 0.00970701  0.18760463 -0.02493127 -0.33571005]\n",
      "[ 0.01345911 -0.00715381 -0.03164547 -0.05099222]\n",
      "[ 0.01331603  0.18840728 -0.03266531 -0.35348919]\n",
      "[ 0.01708417  0.38397812 -0.0397351  -0.65629085]\n",
      "[ 0.02476374  0.1894312  -0.05286091 -0.37637986]\n",
      "[ 0.02855236  0.38526254 -0.06038851 -0.68525043]\n",
      "[ 0.03625761  0.58116858 -0.07409352 -0.99631728]\n",
      "[ 0.04788098  0.38711148 -0.09401986 -0.72779383]\n",
      "[ 0.05562321  0.58339878 -0.10857574 -1.04852553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04544111  0.03400476  0.02749946 -0.01030852]\n",
      "[-0.04476102 -0.16150056  0.02729329  0.2909224 ]\n",
      "[-0.04799103  0.03322181  0.03311174  0.00697087]\n",
      "[-0.04732659 -0.16235898  0.03325115  0.30991432]\n",
      "[-0.05057377 -0.35793852  0.03944944  0.6128955 ]\n",
      "[-0.05773254 -0.55358893  0.05170735  0.9177379 ]\n",
      "[-0.06880432 -0.74937038  0.07006211  1.22621277]\n",
      "[-0.08379173 -0.94532088  0.09458636  1.53999883]\n",
      "[-0.10269815 -1.14144473  0.12538634  1.86063656]\n",
      "[-0.12552704 -0.94790131  0.16259907  1.60936764]\n",
      "[-0.01235173 -0.04285043 -0.00463074  0.00966335]\n",
      "[-0.01320874  0.15233762 -0.00443747 -0.28447703]\n",
      "[-0.01016199  0.34752258 -0.01012701 -0.5785562 ]\n",
      "[-0.00321154  0.54278499 -0.02169814 -0.87441208]\n",
      "[ 0.00764416  0.34796465 -0.03918638 -0.58862911]\n",
      "[ 0.01460346  0.5436128  -0.05095896 -0.89339389]\n",
      "[ 0.02547571  0.34921765 -0.06882684 -0.61715514]\n",
      "[ 0.03246006  0.54523018 -0.08116994 -0.93069692]\n",
      "[ 0.04336467  0.74134826 -0.09978388 -1.24774324]\n",
      "[ 0.05819163  0.93759796 -0.12473875 -1.5699413 ]\n",
      "[-0.03929112  0.03429971 -0.01996186 -0.00353325]\n",
      "[-0.03860513  0.22970217 -0.02003253 -0.30244695]\n",
      "[-0.03401109  0.42510382 -0.02608147 -0.60137977]\n",
      "[-0.02550901  0.23035623 -0.03810906 -0.31702483]\n",
      "[-0.02090189  0.42599968 -0.04444956 -0.62147828]\n",
      "[-0.01238189  0.62171324 -0.05687913 -0.92782253]\n",
      "[ 5.23721362e-05  8.17555111e-01 -7.54355758e-02 -1.23782371e+00]\n",
      "[ 0.01640347  0.62347892 -0.10019205 -0.96969435]\n",
      "[ 0.02887305  0.8197927  -0.11958594 -1.29209545]\n",
      "[ 0.04526891  1.01621451 -0.14542785 -1.61969846]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(10):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print('Episode finished after {} timesteps'.format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box(4,)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "print(env.action_space)\n",
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from gym import spaces\n",
    "space = spaces.Discrete(8)    # Set with 8 elements {0, 1, 2, ..., 7}\n",
    "x = space.sample()\n",
    "print(x)\n",
    "assert space.contains(x)\n",
    "assert space.n == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(5)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 200\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "#             plot_durations()\n",
    "            if i_episode % 20 == 0:\n",
    "                print('This is episode: ', i_episode)\n",
    "                print('The episode last: ', t + 1)\n",
    "                plot_durations()\n",
    "            break\n",
    "            \n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
